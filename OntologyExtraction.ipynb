{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c23798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: prompts in /home/developer/.local/lib/python3.10/site-packages (0.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdd47247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting GEOparse\n",
      "  Using cached GEOparse-2.0.4-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/developer/.local/lib/python3.10/site-packages (from GEOparse) (2.32.3)\n",
      "Requirement already satisfied: pandas>=0.17 in /home/developer/.local/lib/python3.10/site-packages (from GEOparse) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/developer/.local/lib/python3.10/site-packages (from GEOparse) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/developer/.local/lib/python3.10/site-packages (from GEOparse) (4.67.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/developer/.local/lib/python3.10/site-packages (from pandas>=0.17->GEOparse) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/developer/.local/lib/python3.10/site-packages (from pandas>=0.17->GEOparse) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/developer/.local/lib/python3.10/site-packages (from pandas>=0.17->GEOparse) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/developer/.local/lib/python3.10/site-packages (from requests>=2.21.0->GEOparse) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/developer/.local/lib/python3.10/site-packages (from requests>=2.21.0->GEOparse) (2024.12.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/developer/.local/lib/python3.10/site-packages (from requests>=2.21.0->GEOparse) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/developer/.local/lib/python3.10/site-packages (from requests>=2.21.0->GEOparse) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/developer/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.17->GEOparse) (1.17.0)\n",
      "Installing collected packages: GEOparse\n",
      "Successfully installed GEOparse-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install GEOparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2b0e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Using cached openai-1.60.1-py3-none-any.whl (456 kB)\n",
      "Requirement already satisfied: tqdm>4 in /home/developer/.local/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/developer/.local/lib/python3.10/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio in /home/developer/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/developer/.local/lib/python3.10/site-packages (from openai) (2.7.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/developer/.local/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/developer/.local/lib/python3.10/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/developer/.local/lib/python3.10/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/developer/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/developer/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/developer/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/developer/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/developer/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/developer/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/developer/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-1.60.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd3a526f-a0b6-4019-97ea-bc9289bb79f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53874f248ee10cd6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# https://geoparse.readthedocs.io/en/latest/usage.html\n",
    "import os\n",
    "import GEOparse\n",
    "import logging\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4562550e41e5be08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from random import choice, sample\n",
    "from prompts.aspects import annotation_aspects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188f8e379498cd15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Experimental Design and Sample Collection', 'Data Processing and Analysis Methods', 'Quality Control and Filtering', 'Sequencing and Array Platform Details', 'Technical Replicates and Biological Replicates', 'Control and Reference Samples'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_aspects_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd06dd58-4356-42be-9108-e65876b02586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Experimental Design and Sample Collection': '   - Experimental Conditions: Standardize the description of experimental conditions, such as control and treatment groups, time points, dosages, and environmental conditions.\\n   - Sample Characteristics: Ensure detailed and consistent documentation of sample characteristics, including organism strain, age, sex, health status, and housing conditions.',\n",
       " 'Data Processing and Analysis Methods': '- Normalization Techniques: Detail the normalization techniques applied to the data, such as TPM, RPKM, or CPM for RNA-Seq data.\\n   - Statistical Methods: Standardize the description of statistical methods used for data analysis, including differential expression analysis, clustering, and pathway analysis.',\n",
       " 'Quality Control and Filtering': '- Quality Metrics: Include standardized quality control metrics, such as read depth, base quality scores, alignment rates, and duplicate rates.\\n   - Filtering Criteria: Document criteria for data filtering, such as thresholds for quality scores, removal of low-quality reads, and exclusion of certain data points.',\n",
       " 'Sequencing and Array Platform Details': '- Platform Specifications: Standardize metadata related to the sequencing or array platform used, including model, manufacturer, and specific platform ID.\\n   - Library Preparation: Document library preparation protocols in detail, covering aspects like fragmentation, adapter ligation, and PCR amplification conditions.',\n",
       " 'Technical Replicates and Biological Replicates': '- Replicate Information: Clearly document the use of technical and biological replicates, including the number of replicates and how they were processed and analyzed.',\n",
       " 'Control and Reference Samples': '- Control Samples: Ensure detailed metadata for control samples, describing their role and how they were handled compared to experimental samples.\\n   - Reference Genomes: Standardize information on reference genomes or reference datasets used for alignment and comparison.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_aspects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a710d3e8ec549c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'Control and Reference Samples': \n",
    "'- Control Samples: Ensure detailed metadata for control samples, describing their role and how they were handled compared to experimental samples.  \n",
    "- Reference Genomes: Standardize information on reference genomes or reference datasets used for alignment and comparison.'\n",
    "\"\"\"\n",
    "aspect = 'Control and Reference Samples'\n",
    "aspect_details = annotation_aspects_list[aspect]\n",
    "irrelevant_aspects = [x for x in annotation_aspects_list.keys() if x != aspect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d82ed47e52aa38",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "logging.getLogger('GEOparse').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849f5f8466651799",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datasets_df = pd.read_excel('Magalhaes_datasets.xlsx', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d847442a-f3ee-4c42-b22e-6e75716b72b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Species</th>\n",
       "      <th>Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AgeMap</td>\n",
       "      <td>Adrenal Glands</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Microarray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AgeMap</td>\n",
       "      <td>Bone Marrow</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Microarray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgeMap</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Microarray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AgeMap</td>\n",
       "      <td>Eye</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Microarray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GDS1079</td>\n",
       "      <td>Myoblasts</td>\n",
       "      <td>Mouse</td>\n",
       "      <td>Microarray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Study          Tissue Species  Technology\n",
       "0   AgeMap  Adrenal Glands   Mouse  Microarray\n",
       "1   AgeMap     Bone Marrow   Mouse  Microarray\n",
       "2   AgeMap           Brain   Mouse  Microarray\n",
       "3   AgeMap             Eye   Mouse  Microarray\n",
       "4  GDS1079       Myoblasts   Mouse  Microarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "808d0c800156df9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gse_id_list = datasets_df.query(\"Technology=='Microarray' & Study !='AgeMap'\").Study.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31755219-efea-4650-8653-2218bf9e1acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GDS1079',\n",
       " 'GDS1278',\n",
       " 'GDS1279',\n",
       " 'GDS1280',\n",
       " 'GDS1280',\n",
       " 'GDS1311',\n",
       " 'GDS156',\n",
       " 'GDS1647',\n",
       " 'GDS1803',\n",
       " 'GDS2019',\n",
       " 'GDS2082',\n",
       " 'GDS2612',\n",
       " 'GDS2639',\n",
       " 'GDS2681',\n",
       " 'GDS287',\n",
       " 'GDS288',\n",
       " 'GDS2912',\n",
       " 'GDS2929',\n",
       " 'GDS2972',\n",
       " 'GDS2973',\n",
       " 'GDS2996',\n",
       " 'GDS3077',\n",
       " 'GDS3102',\n",
       " 'GDS3102',\n",
       " 'GDS3182',\n",
       " 'GDS355',\n",
       " 'GDS356',\n",
       " 'GDS3620',\n",
       " 'GDS3869',\n",
       " 'GDS3915',\n",
       " 'GDS3939',\n",
       " 'GDS3976',\n",
       " 'GDS399',\n",
       " 'GDS40',\n",
       " 'GDS4019',\n",
       " 'GDS4264',\n",
       " 'GDS4522',\n",
       " 'GDS4523',\n",
       " 'GDS472',\n",
       " 'GDS473',\n",
       " 'GDS4804',\n",
       " 'GDS4858',\n",
       " 'GDS4874',\n",
       " 'GDS4892',\n",
       " 'GDS4904',\n",
       " 'GDS4925',\n",
       " 'GDS520',\n",
       " 'GDS5204',\n",
       " 'GDS5216',\n",
       " 'GDS5217',\n",
       " 'GDS5218',\n",
       " 'GDS5226',\n",
       " 'GDS5286',\n",
       " 'GDS5412',\n",
       " 'GDS707',\n",
       " 'GSE11097',\n",
       " 'GSE11291',\n",
       " 'GSE11291',\n",
       " 'GSE11291',\n",
       " 'GSE12277',\n",
       " 'GSE12480',\n",
       " 'GSE16487',\n",
       " 'GSE19676',\n",
       " 'GSE21681',\n",
       " 'GSE27625',\n",
       " 'GSE32719',\n",
       " 'GSE34378',\n",
       " 'GSE34378',\n",
       " 'GSE34378',\n",
       " 'GSE34378',\n",
       " 'GSE34378',\n",
       " 'GSE35322',\n",
       " 'GSE36192',\n",
       " 'GSE39540',\n",
       " 'GSE40645',\n",
       " 'GSE48911',\n",
       " 'GSE5086',\n",
       " 'GSE56045',\n",
       " 'GSE56580',\n",
       " 'GSE58137',\n",
       " 'GSE61915',\n",
       " 'GSE63060',\n",
       " 'GSE66857',\n",
       " 'GSE69187',\n",
       " 'GSE69832',\n",
       " 'GSE73450',\n",
       " 'GSE74463',\n",
       " 'GSE7958',\n",
       " 'GSE85084']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gse_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5caa8f",
   "metadata": {},
   "source": [
    "- GDS (DataSets): Curated collections of processed data.\n",
    "- GSE (Series): Group of related experiments or samples.\n",
    "- GSM (Sample): Individual sample data within a series.\n",
    "- GSP (Platform): Technology or method used for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c6af60-8456-4734-b866-b7f18ccb086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len: 89\n",
      "Unique Len: 81\n"
     ]
    }
   ],
   "source": [
    "print(f\"Len: {len(gse_id_list)}\")\n",
    "print(f\"Unique Len: {len(set(gse_id_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eeb265d23e7e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "/home/developer/.local/lib/python3.10/site-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gse_list = []\n",
    "i = 0\n",
    "for gse_id in gse_id_list:\n",
    "    # i += 1\n",
    "    if i == 78:\n",
    "        continue\n",
    "    try:\n",
    "        gse_list.append(GEOparse.get_GEO(geo=gse_id, destdir=\"./data/\"))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52af610b-1b6d-4c47-b9d2-5506e79d949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "# Number of file in the ./data\n",
    "files = [f for f in os.listdir(\"./data\") if os.path.isfile(os.path.join(\"./data\", f))]\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf4b49f-482c-498b-ae10-e0109b89485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "print(len(gse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91d2fccb82f268f0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def openai_generate(messages: list, model: str = 'gpt-4', **generation_params):\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        **generation_params\n",
    "    )\n",
    "    return completion#.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20e09d79-311d-42e1-b192-6a9fc5156d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GSM2257446': <SAMPLE: GSM2257446>, 'GSM2257447': <SAMPLE: GSM2257447>, 'GSM2257448': <SAMPLE: GSM2257448>, 'GSM2257449': <SAMPLE: GSM2257449>, 'GSM2257450': <SAMPLE: GSM2257450>, 'GSM2257451': <SAMPLE: GSM2257451>, 'GSM2257452': <SAMPLE: GSM2257452>, 'GSM2257453': <SAMPLE: GSM2257453>, 'GSM2257454': <SAMPLE: GSM2257454>, 'GSM2257455': <SAMPLE: GSM2257455>, 'GSM2257456': <SAMPLE: GSM2257456>, 'GSM2257457': <SAMPLE: GSM2257457>, 'GSM2257458': <SAMPLE: GSM2257458>, 'GSM2257459': <SAMPLE: GSM2257459>, 'GSM2257460': <SAMPLE: GSM2257460>, 'GSM2257461': <SAMPLE: GSM2257461>, 'GSM2257462': <SAMPLE: GSM2257462>, 'GSM2257463': <SAMPLE: GSM2257463>, 'GSM2257464': <SAMPLE: GSM2257464>, 'GSM2257465': <SAMPLE: GSM2257465>, 'GSM2257466': <SAMPLE: GSM2257466>, 'GSM2257467': <SAMPLE: GSM2257467>, 'GSM2257468': <SAMPLE: GSM2257468>, 'GSM2257469': <SAMPLE: GSM2257469>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': ['Female_Young1'],\n",
       " 'geo_accession': ['GSM2257446'],\n",
       " 'status': ['Public on Jan 10 2017'],\n",
       " 'submission_date': ['Aug 02 2016'],\n",
       " 'last_update_date': ['Jan 10 2017'],\n",
       " 'type': ['RNA'],\n",
       " 'channel_count': ['1'],\n",
       " 'source_name_ch1': ['Hippocampus'],\n",
       " 'organism_ch1': ['Mus musculus'],\n",
       " 'taxid_ch1': ['10090'],\n",
       " 'characteristics_ch1': ['strain: C57BL6', 'gender: Female', 'age: Young'],\n",
       " 'treatment_protocol_ch1': ['Mice were aged without any genetic or pharmacological intervention'],\n",
       " 'molecule_ch1': ['total RNA'],\n",
       " 'extract_protocol_ch1': ['RNA was extracted with Trizol reagent, followed by clean-up and DNase I treatment with QIAGEN RNeasy mini kit in accordance with the prescribed protocol provided with the kit. Quality control was performed with Agilent Bioanalyser.'],\n",
       " 'label_ch1': ['Cy3'],\n",
       " 'label_protocol_ch1': ['Biotinylated cRNA were prepared with the Ambion TotalPrep kit for Illumina arrays'],\n",
       " 'hyb_protocol': ['Standard Illumina hybridization protocol'],\n",
       " 'scan_protocol': ['Standard Illumina scanning protocol'],\n",
       " 'description': ['Replicate 1'],\n",
       " 'data_processing': ['We used GenomeStudio V2011.1 Gene Expression Module v1.9.0 for the average normalization.'],\n",
       " 'platform_id': ['GPL6885'],\n",
       " 'contact_name': ['Penn State,,COM'],\n",
       " 'contact_department': ['Genome Sciences Facility'],\n",
       " 'contact_institute': ['Penn State College of Medicine'],\n",
       " 'contact_address': ['500 University Drive'],\n",
       " 'contact_city': ['Hershey'],\n",
       " 'contact_state': ['PA'],\n",
       " 'contact_zip/postal_code': ['17033'],\n",
       " 'contact_country': ['USA'],\n",
       " 'supplementary_file': ['NONE'],\n",
       " 'series_id': ['GSE85084'],\n",
       " 'data_row_count': ['25697']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gse_ = gse_list[-1]\n",
    "print(gse_.gsms)\n",
    "# gsm_ = gse_.gsms[0]\n",
    "# print(gsm_)\n",
    "gsm_sample_ = gse_.gsms['GSM2257446']\n",
    "gsm_sample_.metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515d5d8df88be52",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unique_values = collect_unique_field_values(key='data_processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7931ef7d26532",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('\\n###\\n'.join(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bc9fa08d5ce5da9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from prompts.data_processing import data_processing_constitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f93cc3b543520",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "example_message = '''Raw data (CEL files) were processed using the robust multi-array average (RMA) algorithm and quantile normalization with the Affymetrix Power Tools, \n",
    "version 1.12.0, and platform-specific library files. Differential gene expression was analyzed using descriptive statistics (fold change) and \n",
    "Student’s T-Test method for pairwise comparisons. Genes were prioritized by statistical evidence. \n",
    "In order to create candidate lists for differential gene expression between conditions, \n",
    "we used all genes regulated at least 1.5-fold where differential expression was significant at level 0.05. \n",
    "Type I error inflation was ignored because the p-values were used to prioritize the list rather than being interpreted in a confirmatory sense.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8550f052-e412-4221-9893-0512faa316c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction\\n\\nThis constitution outlines the rules and guidelines that you, as an LLM agent must follow to successfully transform method descriptions into a structured format \\nusing a set of predefined First-Order Logic (FOL) predicates. \\nThe goal is to ensure consistent, accurate, and comprehensive representation of method descriptions.\\n\\nDefinitions\\n\\nMethod Description: A textual description detailing the processes, software, and methodologies used in data processing.\\nPredicate: A logical statement that describes a specific aspect of the method description.\\nConjunction of Predicates: A combination of multiple predicates that together provide a complete representation of a method description.\\nPredicates\\n\\nYou must use the following predicates:\\n\\n - Programming Languages and Software:\\nProgrammingLanguageUsed(Language)\\nSoftwareUsed(Software)\\nSoftwareVersion(Software, Version)\\nPackageUsed(Package)\\nPackageVersion(Package, Version)\\n\\n - Normalization Methods:\\nMethodApplied(Method)\\nCorrectionApplied(Correction)\\n\\n - Data Types and Formats:\\nDataFormat(Format)\\nFileType(Type)\\n\\n - Quality Control and Analysis:\\nQualityControl(QCMethod)\\nDifferentialExpressionAnalysis(DEMethod)\\nGeneAnnotation(AnnotationMethod)\\n\\n - General Information:\\nAdditionalParameter(Parameter, Value)\\n\\n\\nRules for Transformation:\\n\\nIdentify Key Components: Parse the method description to identify all key components such as file types, software, methods, packages, parameters, and quantitative values.\\nApply Relevant Predicates: For each identified component, apply the corresponding predicate(s) from the predefined list.\\nEnsure Completeness: Ensure that all relevant aspects of the method description are covered by predicates, including software versions and quantitative values.\\nMaintain Order and Structure: Organize the predicates in a logical order that reflects the sequence and relationships within the method description.\\nHandle Quantitative Information: Explicitly capture all quantitative details such as p-value cut-offs, fold change cut-offs, and specific parameter values using the AdditionalParameter predicate.\\nAccount for Platform-Specific Details: Include any platform-specific library files or settings mentioned in the method description.\\nOutput format: Return only set of predicates as an output.\\n\\n\\nExample Transformation\\n\\nMethod Description: \"Affymetrix GeneChip microarray suite software was used for washing and scanning. Expression summaries were calculated using an analysis algorithm adapted from Choe et al. (2005) [PMID: 15693945], in the sequence of \\'Background correction (MAS5), Quantile normalization (RMA), Perfect match adjustment (MAS5), Median polish (RMA), LOESS normalization.\\'\"\\n\\nTransformed Predicates:\\nSoftwareUsed(AffymetrixGeneChipMicroarraySuite)\\nMethodApplied(BackgroundCorrectionMAS5)\\nMethodApplied(QuantileNormalizationRMA)\\nMethodApplied(PerfectMatchAdjustmentMAS5)\\nMethodApplied(MedianPolishRMA)\\nMethodApplied(LOESSNormalization)\\n\\n\\nImplementation Guidelines:\\n\\nConsistency: Ensure that similar method descriptions yield consistent sets of predicates.\\nAccuracy: Accurately reflect the content and details of the method description.\\nComprehensiveness: Include all relevant information from the method description.\\nClarity: Maintain clear and understandable predicate expressions.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processing_constitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fbfff23140dba29",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "messages =[\n",
    "    {'role':'system', 'content':data_processing_constitution},\n",
    "    {'role':'user', 'content':example_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5a722c085a4ecea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileType(CEL)\n",
      "MethodApplied(RobustMultiArrayAverage)\n",
      "MethodApplied(QuantileNormalization)\n",
      "SoftwareUsed(AffymetrixPowerTools)\n",
      "SoftwareVersion(AffymetrixPowerTools, 1.12.0)\n",
      "DifferentialExpressionAnalysis(DescriptiveStatisticsFoldChange)\n",
      "DifferentialExpressionAnalysis(StudentsTTest)\n",
      "AdditionalParameter(FoldRegulationCutOff, 1.5)\n",
      "AdditionalParameter(SignificanceLevel, 0.05)\n",
      "QualityControl(TypeIErrorInflationIgnored)\n"
     ]
    }
   ],
   "source": [
    "completion = openai_generate(messages, temperature=1.0)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89091c86e4257e3e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "example_extraction_message = '''Cardiac ventricle total RNA from 10 young (4-6 month) and 10 old (25-28 month) mice was prepared and hybridized to Affymetrix™GeneChip® MOE430 2.0 arrays. \n",
    "Total RNA was prepared from frozen tissues using the Qiagen RNeasy kit following homogenization in Trizol (Invitrogen). Genomic DNA was prepared using the Qiagen Dneasy kit.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb7dbef5ea5572ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from prompts.extraction_protocol import extraction_protocol_constitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c70869a4de7032a4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "messages =[\n",
    "    {'role':'system', 'content':extraction_protocol_constitution},\n",
    "    {'role':'user', 'content':example_extraction_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e0ea80a0d290355",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Predicates:\n",
      "SampleType(CardiacVentricleTotalRNA)\n",
      "SourceInformation(Mice, CardiacVentricle)\n",
      "KitUsed(QiagenRNeasyKit)\n",
      "Manufacturer(Qiagen, RNeasyKit)\n",
      "ReagentUsed(Trizol)\n",
      "Manufacturer(Invitrogen, Trizol)\n",
      "KitUsed(QiagenDNeasyKit)\n",
      "Manufacturer(Qiagen, DNeasyKit)\n",
      "DeviceUsed(AffymetrixGeneChipMOE4302.0)\n",
      "Manufacturer(Affymetrix, GeneChipMOE4302.0)\n"
     ]
    }
   ],
   "source": [
    "completion = openai_generate(messages, temperature=1.0)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a3b98b4b49370c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def format_metadata(gse, gsm):\n",
    "    # GSE fields\n",
    "    gse_fields = ['summary', 'overall_design', 'type']\n",
    "    \n",
    "    # GSM fields\n",
    "    gsm_fields= [\n",
    "        'source_name_ch1', 'organism_ch1', 'characteristics_ch1',\n",
    "        'treatment_protocol_ch1', 'molecule_ch1', 'extract_protocol_ch1',\n",
    "        'label_ch1', 'label_protocol_ch1', 'hyb_protocol_ch1', \n",
    "        'scan_protocol', 'data_processing'\n",
    "    ]\n",
    "    \n",
    "    metadata_str = []\n",
    "    \n",
    "    # Fetch and print GSE metadata\n",
    "    for field in gse_fields:\n",
    "        value = gse.metadata.get(field, ['N/A'])[0]  # fetch metadata if available, else 'N/A'\n",
    "        metadata_str.append(f\"GSE {field.replace('_', ' ').title()}: {value}\")  # add formatted string\n",
    "    \n",
    "    # Fetch and print GSM metadata\n",
    "    for field in gsm_fields:\n",
    "        value = gsm.metadata.get(field, ['N/A'])[0]  # fetch metadata if available, else 'N/A'\n",
    "        metadata_str.append(f\"GSM {field.replace('_', ' ').title()}: {value}\")  # add formatted string\n",
    "\n",
    "    return \"\\n\".join(metadata_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddc8313aaf364fc2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n"
     ]
    }
   ],
   "source": [
    "field_values = set()\n",
    "for gse in gse_list:\n",
    "    try:\n",
    "        for gsm in gse.gsms:\n",
    "            gsm_sample = gse.gsms[gsm]\n",
    "            field_values.add(format_metadata(gse, gsm_sample))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "327c98bc0826ea7f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(field_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4fa08ec-6998-491e-90a5-5deaed8f054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE Summary: The MESA Epigenomics and Transcriptomics Study has been launched to investigate potential gene expression regulatory methylation sites in humans by examining the association between CpG methylation and gene expression in purified human monocytes from a large study population (community-dwelling participants in the Multi-Ethnic Study of Atherosclerosis (MESA)).\n",
      "GSE Overall Design: The current study is particularly focused on the relationships between transcriptomics and methylomics with age.\n",
      "GSE Type: Expression profiling by array\n",
      "GSM Source Name Ch1: CD14+ cell\n",
      "GSM Organism Ch1: Homo sapiens\n",
      "GSM Characteristics Ch1: ChIP: 6334167259\n",
      "GSM Treatment Protocol Ch1: Not applicable\n",
      "GSM Molecule Ch1: total RNA\n",
      "GSM Extract Protocol Ch1: Blood was initially collected in sodium heparin-containing Vacutainer CPTTM cell separation tubes (Becton Dickinson, Rutherford, NJ) to separate peripheral blood mononuclear cells from other elements within 2 hours from blood draw. Subsequently, monocytes were isolated with the anti-CD14 coated magnetic beads, respectively, using AutoMACs automated magnetic separation unit (Miltenyi Biotec, Bergisch Gladbach, Germany).  DNA and RNA were isolated from samples simultaneously using the AllPrep DNA/RNA Mini Kit (Qiagen, Inc., Hilden, Germany).\n",
      "GSM Label Ch1: biotin\n",
      "GSM Label Protocol Ch1: The Illumina TotalPrep-96 RNA Amplification Kit (Ambion/Applied Biosystems, DaeMStadt, Germany) was used for reverse transcription, and amplification with 500 ng of input total RNA (at 11ul).\n",
      "GSM Hyb Protocol Ch1: N/A\n",
      "GSM Scan Protocol: Illumina Bead Array Reader\n",
      "GSM Data Processing: Data corrected for local background were obtained from Illumina’s proprietary software GenomeStudio. QC analyses and bead type summarization (average bead signal for each type after outlier removal) were performed using the beadarray package (25). Detection P-values were computed using the negative controls on the array. The neqc function of the limma (26) package was used to perform a normal-exponential convolution model analysis to estimate non-negative signal, quantile normalization using all probes (gene and control, detected and not detected) and samples, addition of a recommended (small) offset, log2 transformation, and elimination of control probe data from the normalized expression matrix.\n"
     ]
    }
   ],
   "source": [
    "print(next((iter(field_values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac3ecbc97aececfd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fb61a65f9db9b85",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "predicate_instruction = \"\"\"Introduction and Goal:\n",
    "\n",
    "The primary goal of this task is to systematically extract and standardize predicates from the metadata of GSE (Gene Expression Omnibus Series) and GSM (Gene Expression Omnibus Samples) descriptions. \n",
    "These predicates will be used to automate the metadata standardization process across various genomics datasets, facilitating efficient and consistent data analysis for meta-studies. \n",
    "By defining clear predicates based on experimental design and sample collection, we aim to create a structured queryable framework that enhances data retrieval and analysis capabilities in biological research databases.\n",
    "\n",
    "Task Description:\n",
    "\n",
    "Generate a comprehensive list of predicates focused on {aspect} from GSE and GSM descriptions. Ensure each predicate is standardized, uses controlled vocabulary, and adheres strictly to the concepts outlined in the provided guidelines. \n",
    "This structured extraction will enable automated systems to better understand and categorize data entries, significantly improving the accuracy and speed of meta-analyses.\n",
    "\n",
    "Guidelines:\n",
    "Focus on Key Concepts from the following list:\n",
    "{aspect_details}\n",
    "\n",
    "Ensure that the list of predicates is comprehensive and covers all concepts from the list above. \n",
    "\n",
    "\n",
    "Define Predicates:\n",
    "\n",
    "For each identified relationship or attribute, define a predicate. Ensure the predicate name is descriptive of the relationship or attribute it represents.\n",
    "Create separate predicates for distinctive properties not entailed with each other (for example, strain and age).\n",
    "Avoid using free-text entries in the predicates.\n",
    "Exclude predicates that are not related to the specified key concepts. Avoid including predicates related to the following aspects: {irrelevant_aspects_combined}.\n",
    "Only include predicates relevant to {aspect}. \n",
    "Do not generate predicates for generic attributes such as age or sex unless explicitly related to the sample characteristics described in the guidelines.\n",
    "Do not generate predicates for quantitative measures such as temporal data, dosage, concentration, volume, mass, temperature, speed, time duration, and frequency. These formats are already standardized and provided. Focus on other attributes and relationships related to the specified key concepts.\n",
    "\n",
    "\n",
    "\n",
    "Standardize Quantitative Data:\n",
    "\n",
    "Ensure that quantitative data is standardized in a consistent format, such as TimeFrame(value, unit).\n",
    "Use the following formats for other quantitative measures:\n",
    "List of Standardized Quantitative Measures\n",
    "Temporal Data\n",
    "\n",
    "Format: TimeFrame(value, unit)\n",
    "Example: TimeFrame(32, Years)\n",
    "Range Format: TimeFrame(Range(minValue, maxValue), unit)\n",
    "Range Example: TimeFrame(Range(32, 39), Years)\n",
    "Dosage\n",
    "\n",
    "Format: Dosage(value, unit)\n",
    "Example: Dosage(1.0, gPerKg)\n",
    "Range Format: Dosage(Range(minValue, maxValue), unit)\n",
    "Range Example: Dosage(Range(0.5, 1.0), gPerKg)\n",
    "Concentration\n",
    "\n",
    "Format: Concentration(value, unit)\n",
    "Example: Concentration(0.1, Molar)\n",
    "Range Format: Concentration(Range(minValue, maxValue), unit)\n",
    "Range Example: Concentration(Range(0.05, 0.1), Molar)\n",
    "Volume\n",
    "\n",
    "Format: Volume(value, unit)\n",
    "Example: Volume(10, mL)\n",
    "Range Format: Volume(Range(minValue, maxValue), unit)\n",
    "Range Example: Volume(Range(5, 10), mL)\n",
    "Mass\n",
    "\n",
    "Format: Mass(value, unit)\n",
    "Example: Mass(2.5, mg)\n",
    "Range Format: Mass(Range(minValue, maxValue), unit)\n",
    "Range Example: Mass(Range(1.0, 2.5), mg)\n",
    "Temperature\n",
    "\n",
    "Format: Temperature(value, unit)\n",
    "Example: Temperature(37, Celsius)\n",
    "Range Format: Temperature(Range(minValue, maxValue), unit)\n",
    "Range Example: Temperature(Range(35, 37), Celsius)\n",
    "Speed\n",
    "\n",
    "Format: Speed(value, unit)\n",
    "Example: Speed(100, rpm)\n",
    "Range Format: Speed(Range(minValue, maxValue), unit)\n",
    "Range Example: Speed(Range(80, 100), rpm)\n",
    "Time Duration\n",
    "\n",
    "Format: Duration(value, unit)\n",
    "Example: Duration(30, Minutes)\n",
    "Range Format: Duration(Range(minValue, maxValue), unit)\n",
    "Range Example: Duration(Range(20, 30), Minutes)\n",
    "Frequency\n",
    "\n",
    "Format: Frequency(value, unit)\n",
    "Example: Frequency(3, perDay)\n",
    "Range Format: Frequency(Range(minValue, maxValue), unit)\n",
    "Range Example: Frequency(Range(2, 3), perDay)\n",
    "\n",
    "Standardize Software versions:\n",
    "Ensure that versions of the software related to {aspect} are standardized in a consistent format.\n",
    "Use the following predicate:\n",
    "Format: SoftwareVersion(softwareTitle, versionNumber)\n",
    "Example: SoftwareVersion(AffymetrixPowerTools, 1.12.0)\n",
    "\n",
    "Format the Output:\n",
    "\n",
    "Generate a list of predicates.\n",
    "Provide a brief description of what each predicate represents.\n",
    "Include an example for each predicate.\n",
    "Refrain from using sample as an argument in predicates.\n",
    "Output nothing but a list of predicates according to the provided format. Start right away with the definition of the first predicate.\n",
    "\n",
    "Output format example:\n",
    "\n",
    "Definition: somePredicate(argument)\n",
    "Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: somePredicate(ExampleArgument)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c171eec9dbc375cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(predicate_instruction, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37744c3747a8eda2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "SAMPLING_SIZE=150\n",
    "N_TRIALS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86ac54aa617de362",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "refinement_prompt = \"\"\"You are given multiple lists of predicates extracted from various sets of GSE (Gene Expression Omnibus Series) and GSM (Gene Expression Omnibus Samples) metadata descriptions. These predicates are related to {aspect}. Your task involves several key steps to refine and consolidate these predicates into a single, standardized list:\n",
    "\n",
    "Merge and Deduplicate: Combine all the provided lists into one unified list. Identify and remove any duplicate predicates, ensuring that synonyms and nearly identical concepts are consolidated into a single entry. Aim for a clean, non-redundant list that captures the essence of each predicate without repetition.\n",
    "\n",
    "Standardize Format and Terminology: Review the merged list for consistency in naming conventions, formatting, and descriptions. Adjust the predicates to ensure they align with the standardized formats discussed in the guidelines. This includes using controlled vocabulary and adhering to a consistent structural format. Use adjustment examples below.\n",
    "\n",
    "Adjustment examples:\n",
    "Before: somePredicate(\"free text argument\")\n",
    "After: somePredicate(VariableLikeArgument)\n",
    "\n",
    "Before: somePredicate(Argument With Spaces)\n",
    "After: somePredicate(ArgumentWithoutSpaces)\n",
    "\n",
    "Before: somePredicate(argument_with_underscore)\n",
    "After: somePredicate(CamelCaseArgument)\n",
    "\n",
    "Validate and Refine: Ensure that each predicate in the list strictly pertains to the key concepts of {aspect}. Remove any predicates that do not conform to these guidelines or that address unrelated topics such as the following: {irrelevant_aspects_combined}. Focus on refining predicates to be as specific and relevant as possible.\n",
    "\n",
    "Format the Final Output: Organize the final list of predicates into a structured format, with definition of each predicate followed by its brief, clear description and an example of usage. Output nothing but a list of predicates in the format specified below. Start with definition of the first predicate right away.\n",
    "\n",
    "Output format example:\n",
    "\n",
    "Definition: somePredicate(argument)\n",
    "Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: somePredicate(ExampleArgument)\n",
    "\n",
    "Definition: anotherPredicate(argument)\n",
    "Description: another predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: anotherPredicate(AnotherArgument)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c72bf25-3f38-4838-986b-de819f472fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(field_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d035a853aadb7bcc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def extract_predicates(aspect, n_trials, sampling_size):\n",
    "    aspect_details = annotation_aspects_list[aspect]\n",
    "    irrelevant_aspects = [x for x in annotation_aspects_list.keys() if x != aspect] \n",
    "    predicate_list = []\n",
    "    for _ in range(n_trials):\n",
    "        input_samples_combined = \"List of examples to extract predicates from:\\n\"+\"\\n\\n\\n\".join(sample((list(field_values)), sampling_size))\n",
    "        resp = openai_generate([\n",
    "            {\"role\":'system',\n",
    "             'content':predicate_instruction.format(aspect=aspect,\n",
    "                                                    aspect_details=aspect_details,\n",
    "                                                    irrelevant_aspects_combined='\\n'.join(irrelevant_aspects)\n",
    "                                                    )},\n",
    "            {'role':'user',\n",
    "             'content':input_samples_combined}\n",
    "        ], model='gpt-4o')\n",
    "        predicate_list.append(resp.choices[0].message.content)\n",
    "    \n",
    "    combined_predicates = \"Draft predicate lists:\\n\"'\\n\\n###\\n'.join(predicate_list)\n",
    "    resp = openai_generate([\n",
    "            {\"role\":'system', 'content':refinement_prompt.format(aspect=aspect,\n",
    "                                                    aspect_details=aspect_details,\n",
    "                                                    irrelevant_aspects_combined='\\n'.join(irrelevant_aspects)\n",
    "                                                    )},\n",
    "            {'role':'user', 'content':combined_predicates}\n",
    "        ], model='gpt-4o')\n",
    "    \n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7cad223c-28f0-4787-9ba7-1bd8ff238ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Experimental Design and Sample Collection', 'Data Processing and Analysis Methods', 'Quality Control and Filtering', 'Sequencing and Array Platform Details', 'Technical Replicates and Biological Replicates', 'Control and Reference Samples'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_aspects_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "779c20463d5fded6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for aspect in annotation_aspects_list.keys():\n",
    "    predicates = extract_predicates(aspect, 1, 20)\n",
    "    with open(\"./output/\"+aspect+\".txt\", 'w') as f:\n",
    "        f.write(predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4914d84eb5d8136",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Predicate collection with each annotation_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc9b7a3c76af39",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gsm_sample.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20eec2a094b16c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_unique_gsm_field_values(key='data_processing'):\n",
    "    field_values = set()\n",
    "    for gse in gse_list:\n",
    "        try:\n",
    "            for gsm in gse.gsms:\n",
    "                sample = gse.gsms[gsm]\n",
    "                field_values.update(set(sample.metadata[key]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return field_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5fecdef942e129",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gsm_metadata_fields = ['treatment_protocol_ch1', 'extract_protocol_ch1', 'label_protocol_ch1', 'hyb_protocol', 'scan_protocol', 'data_processing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918add88c69c5463",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "field = 'data_processing'\n",
    "unique_values = collect_unique_gsm_field_values(field)\n",
    "data_string = \"\\n###\\n\".join(list(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4222e6fbb880797",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48064e473961a1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "field_prompt=\"\"\"Below are multiple occurrences of the field {field} from metadata of various studies from GEO, separated by ###. The goal is to create a set of First-Order Logic (FOL) predicates to parse these protocols, ensuring they are standardized in a machine-readable format. List all aspects from the data needed to construct these predicates. Ensure the list is complete and non-redundant. Output only the list and start with the first element.\n",
    "{data_string}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f7a3d1a463d1a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aspect_message = openai_generate([\n",
    "            {\"role\":'user', 'content':field_prompt.format(field=field,\n",
    "                                                          data_string=data_string\n",
    "                                                    )},\n",
    "        ], model='gpt-4')\n",
    "print(aspect_message.choices[0].message.content)\n",
    "predicate_message = openai_generate([\n",
    "            {\"role\":'user', 'content':field_prompt.format(field=field,\n",
    "                                                          data_string=data_string\n",
    "                                                    )},\n",
    "    {\"role\":\"assistant\", 'content':resp.choices[0].message.content},\n",
    "    {\"role\":'user', 'content':'''Now generate a list of predicates to cover this list. Use the following format:\n",
    "Definition: somePredicate(argument)\n",
    "Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: somePredicate(ExampleArgument)'''\n",
    "                              }\n",
    "        ], model='gpt-4', temperature=0.0)\n",
    "print(predicate_message.choices[0].message.content)\n",
    "parsing_message = openai_generate([\n",
    "            {\"role\":'user', 'content':field_prompt.format(field=field,\n",
    "                                                          data_string=data_string\n",
    "                                                    )},\n",
    "    {\"role\":\"assistant\", 'content':resp.choices[0].message.content},\n",
    "    {\"role\":'user', 'content':'Now generate a list of predicates to cover this list.'},\n",
    "    {\"role\":\"assistant\", 'content':resp2.choices[0].message.content},\n",
    "    {\"role\":'user', 'content':'Now parse each input metadata into FOL using constructed predicates. Include original text in your output. Make sure to eliminate freetext arguments and format arguments in camelcase and are not quoted.'},\n",
    "        ], model='gpt-4')\n",
    "print(parsing_message.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3a9c160cc5d6a382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:34:56.281157Z",
     "start_time": "2024-07-15T11:34:56.269739Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def extract_field_predicates(field: str) -> Dict[str, str]:\n",
    "    unique_values = collect_unique_gsm_field_values(field)\n",
    "    data_string = \"\\n###\\n\".join(list(unique_values))\n",
    "    message_list = []\n",
    "    field_prompt = \"\"\"Below are multiple occurrences of the field {field} from metadata of various studies from GEO, separated by ###. The goal is to create a set of First-Order Logic (FOL) predicates to parse these protocols, ensuring they are standardized in a machine-readable format. List all aspects from the data needed to construct these predicates. Ensure the list is complete and non-redundant. Output only the list and start with the first element.\n",
    "    {data_string}\n",
    "    \"\"\"\n",
    "    message_list.append({\"role\": 'user', 'content': field_prompt.format(field=field, data_string=data_string)})\n",
    "    aspect_message = openai_generate(message_list, model='gpt-4')\n",
    "\n",
    "    # Extracting the content of the aspect_message\n",
    "    aspect_content = aspect_message.choices[0].message.content\n",
    "    # appending the aspect message to the message list\n",
    "    message_list.append({\"role\": \"assistant\", 'content': aspect_content})\n",
    "\n",
    "    message_list.append({\n",
    "        \"role\": 'user',\n",
    "        'content': '''Now generate a list of predicates to cover this list. Use the following format:\n",
    "        Definition: somePredicate(argument)\n",
    "        Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "        Example: somePredicate(ExampleArgument)'''\n",
    "    })\n",
    "    predicate_message = openai_generate(message_list, model='gpt-4', temperature=0.0)\n",
    "\n",
    "    # Extracting the content of the predicate_message\n",
    "    predicate_content = predicate_message.choices[0].message.content\n",
    "    # appending the predicate message to the message list\n",
    "    message_list.append({\"role\": \"assistant\", 'content': predicate_content})\n",
    "\n",
    "    message_list.append({\n",
    "        \"role\": 'user',\n",
    "        'content': 'Now parse each input metadata into FOL using constructed predicates. Include original text in your output. Make sure to eliminate freetext arguments and format arguments in camelcase and are not quoted.'\n",
    "    })\n",
    "    parsing_message = openai_generate(message_list, model='gpt-4')\n",
    "\n",
    "    # Extracting the contents of the parsing_message\n",
    "    parsing_content = parsing_message.choices[0].message.content\n",
    "\n",
    "    return {\"aspects\": aspect_content, \"predicates\": predicate_content, \"parsed\": parsing_content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9dd20579d4969ff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:36:35.327265Z",
     "start_time": "2024-07-15T11:34:56.754949Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'hyb_protocol'\n"
     ]
    }
   ],
   "source": [
    "content = extract_field_predicates('hyb_protocol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6cebe579e8a1c62a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:37:24.774937Z",
     "start_time": "2024-07-15T11:37:24.769137Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Protocol Name or Source\n",
      "2. Hybridization procedure\n",
      "3. Temperature for Hybridization\n",
      "4. Duration of Hybridization\n",
      "5. Type of RNA \n",
      "6. Quantity of RNA\n",
      "7. Type of Chip or Array\n",
      "8. Washing and Staining procedure\n",
      "9. Fluidic Station used\n",
      "10. Manufacturer of Materials\n",
      "11. Hybridization Kit Used\n",
      "12. Address/location of Manufacturer\n",
      "13. Type of DNA (if any)\n",
      "14. Labeling method for RNA or DNA\n",
      "15. Amplification of cRNA\n",
      "16. Biotinylation of cRNA\n",
      "17. Fragmentation of cRNA and its quantity.\n"
     ]
    }
   ],
   "source": [
    "print(content['aspects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c4d69ec8bc8055b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:22:47.240348Z",
     "start_time": "2024-07-15T12:22:47.219621Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"According to Illumina protocols\"\n",
      "protocolName(IlluminaProtocols)\n",
      "\n",
      "2. \"Following fragmentation, cRNA were hybridized onto the Affymetrix GeneChip Mouse Genome 430 2.0 arrays using the standard Affymetrix protocol. GeneChips were washed and stained in the Affymetrix Fluidics Station 450.\"\n",
      "hybridizationProcedure(HybridizedAffymetrixGeneChipMouseGenome430Arrays)\n",
      "rnaType(CRNA)\n",
      "chipType(AffymetrixGeneChipMouseGenome430)\n",
      "washingProcedure(WashedAndStainedAffymetrixFluidicsStation450)\n",
      "fluidicStation(AffymetrixFluidicsStation450)\n",
      "\n",
      "3. \"700 ng of biotinylated cRNA was hybridized to a BeadChip at 580C for 16-17 hours.\"\n",
      "rnaQuantity(700Ng)\n",
      "rnaType(BiotinylatedCRNA)\n",
      "hybridizationProcedure(HybridizedToBeadChip)\n",
      "hybridizationTemperature(580C)\n",
      "hybridizationDuration(16To17Hours)\n",
      "\n",
      "4. \"Standard Illumina protocol\"\n",
      "protocolName(StandardIllumina)\n",
      "\n",
      "5. \"Affymetrix Eukaryotic Target Hybridization protocol for 100 Format midi arrays (GeneChip® Expression Analysis Technical Manual 701021 Rev. 5)\"\n",
      "protocolName(AffymetrixEukaryoticTargetHybridization)\n",
      "chipType(FormatMidiArrays)\n",
      "\n",
      "6. \"According to the manufacturer's instructions.\"\n",
      "protocolName(ManufacturersInstructions)\n",
      "\n",
      "7. \"Following fragmentation, 10 ug of cRNA were hybridized for 16 hr at 45C on Affymetrix mouse 430 2.0 Array. GeneChips were washed and stained in the Affymetrix Fluidics Station 400.\"\n",
      "cRNAfragmentation(Fragmented10UgCRNA)\n",
      "hybridizationDuration(16Hr)\n",
      "hybridizationTemperature(45C)\n",
      "chipType(AffymetrixMouse430Array)\n",
      "washingProcedure(WashedAndStainedAffymetrixFluidicsStation400)\n",
      "fluidicStation(AffymetrixFluidicsStation400)\n",
      "\n",
      "8. \"750 ng of amplified and Cy3-labelled RNA were used directly hybridized on the Beadchips for 16 hours at 58°C following Illumina’s instructions. Beadchips were then washed following Illumina's protocol.\"\n",
      "rnaQuantity(750Ng)\n",
      "rnaType(AmplifiedAndCy3LabelledRNA)\n",
      "hybridizationProcedure(HybridizedToBeadchips)\n",
      "hybridizationDuration(16Hrs)\n",
      "hybridizationTemperature(58C)\n",
      "washingProcedure(WashedBeadchipsIlluminaProtocol) \n",
      "\n",
      "9. \"The RNA was hybridized to the Human Genome U133A 2.0 Array (Affymetrix).\"\n",
      "hybridizationProcedure(HybridizedToHumanGenomeArray)\n",
      "rnaType(RNA)\n",
      "chipType(HumanGenomeU133AArray) \n",
      "\n",
      "10. \"Standard Illumina hybridization protocol\"\n",
      "protocolName(StandardIlluminaHybridization)\n",
      "\n",
      "11. \"The standard hybridization protocol was used as recommended by Affymterix.\"\n",
      "protocolName(StandardHybridization)\n",
      "\n",
      "12. \"Purified RNA was labeled and hybridized to RAE 230 V2.0 gene chips (one chip per region per animal) by the NIH core facility.\"\n",
      "rnaType(PurifiedRNA)\n",
      "chipType(RAE230V2GeneChips)\n",
      "hybridizationProcedure(LabeledAndHybridizedToRAE230V2)\n",
      "\n",
      "13. \"Following fragmentation, 15 microg of cRNA were hybridized for 16 hr at 45C on Affymetrix HU-133 2.0 GeneChip array.\"\n",
      "cRNAfragmentation(Fragmented15MicrogCRNA)\n",
      "hybridizationDuration(16Hr)\n",
      "hybridizationTemperature(45C)\n",
      "chipType(AffymetrixHU1332GeneChipArray)\n",
      "\n",
      "14. \"Illumina Whole Genome Gene Expression\"\n",
      "protocolName(IlluminaWholeGenomeGeneExpression)\n",
      "\n",
      "15. \"Standard Affymetrix procedures\"\n",
      "protocolName(StandardAffymetrix)\n",
      "\n",
      "16. \"GeneChip Human Genome U133_Plus_2.0 (Affymetrix) were hybridized with 10 µg amplified RNA and washed with a fluidics station 450 (Affymetrix).\"\n",
      "chipType(GeneChipHumanGenomeU133Plus2)\n",
      "rnaQuantity(10Microg)\n",
      "rnaType(AmplifiedRNA)\n",
      "hybridizationProcedure(HybridizedWithAmplifiedRNA)\n",
      "fluidicStation(AffymetrixFluidicsStation450)\n",
      "\n",
      "17. \"cDNA was synthesized from 200ng total RNA using TotalPrep™ RNA Amplification Kit (Ambion) which was followed by amplification and biotinylation of cRNA and hybridization.\"\n",
      "dnaType(CDNA)\n",
      "rnaQuantity(200Ng)\n",
      "rnaType(TotalRNA)\n",
      "hybridizationProcedure(AmplificationAndBiotinylationOfCRNAAndHybridization)\n",
      "\n",
      "18. \"Following fragmentation 10ug of cRNA were hybridized on Rat Expression 230 2.0 Genechips. GeneChips were washed and stained in the Affymetrix Fluidics Station 450.\"\n",
      "cRNAfragmentation(Fragmented10UgCRNA)\n",
      "hybridizationProcedure(HybridizedOnRatExpression230Genechips)\n",
      "chipType(RatExpression230Genechips)\n",
      "washingProcedure(WashedAndStainedInAffymetrixFluidicsStation450)\n",
      "fluidicStation(AffymetrixFluidicsStation450)\n",
      "\n",
      "19. \"Samples were hybridized according to the Affymetrix protocol\"\n",
      "hybridizationProcedure(HybridizedAccordingToAffymetrixProtocol)\n",
      "\n",
      "20. \"The labeled cDNA was hybridized to the Mouse GeneChip 430 2.0 (Affymetrix, Santa Clara, CA, USA). The GeneChip Hybridization, Wash and Stain Kit (Affymetrix, CA) was used for the hybridizations according to the protocol of the manufacturer.\"\n",
      "dnaType(LabeledCDNA)\n",
      "hybridizationProcedure(HybridizedToMouseGeneChip430)\n",
      "chipType(MouseGeneChip430)\n",
      "hybridizationKit(GeneChipHybridizationWashAndStainKit)\n"
     ]
    }
   ],
   "source": [
    "print(content['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe15d8d4c5315fc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53874f248ee10cd6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import GEOparse\n",
    "import logging\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562550e41e5be08",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_TRIALS = 10\n",
    "SAMPLING_SIZE = 150\n",
    "\n",
    "from random import choice, sample\n",
    "from prompts.aspects import annotation_aspects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f8e379498cd15",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotation_aspects_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a710d3e8ec549c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aspect = 'Control and Reference Samples'\n",
    "aspect_details = annotation_aspects_list[aspect]\n",
    "irrelevant_aspects = [x for x in annotation_aspects_list.keys() if x != aspect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d82ed47e52aa38",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.getLogger('GEOparse').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f5f8466651799",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets_df = pd.read_excel('Magalhaes_datasets.xlsx', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d0c800156df9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gse_id_list = datasets_df.query(\"Technology=='Microarray' & Study !='AgeMap'\").Study.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb265d23e7e455",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gse_list = []\n",
    "for gse_id in gse_id_list:\n",
    "    try:\n",
    "        gse_list.append(GEOparse.get_GEO(geo=gse_id, destdir=\"./data/\"))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2fccb82f268f0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def openai_generate(messages: list, model: str = 'gpt-4', **generation_params):\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        **generation_params\n",
    "    )\n",
    "    return completion#.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3641c923530b0b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_metadata(gse, gsm):\n",
    "    # GSE Fields\n",
    "    # 'title' : The title of the Gene Expression Omnibus (GEO) series (GSE)\n",
    "    gse_title = gse.metadata['title'][0] if 'title' in gse.metadata else 'N/A'\n",
    "    \n",
    "    # 'summary' : Brief summary of the experiment conducted in the GSE\n",
    "    gse_summary = gse.metadata['summary'][0] if 'summary' in gse.metadata else 'N/A'\n",
    "    \n",
    "    # 'keywords' : Keywords associated with the GSE\n",
    "    gse_keywords = gse.metadata['keywords'][0] if 'keywords' in gse.metadata else 'N/A'\n",
    "    \n",
    "    # 'overall_design' : Overall design of the experiment conducted in the GSE\n",
    "    gse_overall_design = gse.metadata['overall_design'][0] if 'overall_design' in gse.metadata else 'N/A'\n",
    "\n",
    "    # GSM Fields\n",
    "    # 'title' : The title of the individual sample (GSM)\n",
    "    gsm_title = gsm.metadata['title'][0] if 'title' in gsm.metadata else 'N/A'\n",
    "    \n",
    "    # 'source_name_ch1' : Biological source from which the sample was taken\n",
    "    gsm_source_name_ch1 = gsm.metadata['source_name_ch1'][0] if 'source_name_ch1' in gsm.metadata else 'N/A'\n",
    "    \n",
    "    # 'organusm_ch1' : The organism from which the sample was taken\n",
    "    gsm_organism_ch1 = gsm.metadata['organism_ch1'][0] if 'organism_ch1' in gsm.metadata else 'N/A'\n",
    "    \n",
    "    # 'characteristics_ch1' : Characteristics and traits of the sample\n",
    "    gsm_characteristics_ch1 = gsm.metadata['characteristics_ch1'][0] if 'characteristics_ch1' in gsm.metadata else 'N/A'\n",
    "    \n",
    "    # 'description' : Additional information about the sample\n",
    "    gsm_description = gsm.metadata['description'][0] if 'description' in gsm.metadata else 'N/A'\n",
    "\n",
    "    # Combine everything into a single string\n",
    "    metadata_str = f\"GSE Title: {gse_title}\\nGSE Summary: {gse_summary}\\nGSE Keywords: {gse_keywords}\\nGSE Overall Design: {gse_overall_design}\\n\"\n",
    "    metadata_str += f\"GSM Organism: {gsm_organism_ch1}\\nGSM Characteristics: {gsm_characteristics_ch1}\\nGSM Description: {gsm_description}\"\n",
    "\n",
    "    return metadata_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27217fe18a9bf5ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsm_sample.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515d5d8df88be52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_values = collect_unique_field_values(key='data_processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7931ef7d26532",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('\\n###\\n'.join(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018ded1f9baefa2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541eaa605c3d8d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_tokens_from_string(, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9fa08d5ce5da9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prompts.data_processing import data_processing_constitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f93cc3b543520",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_message = '''Raw data (CEL files) were processed using the robust multi-array average (RMA) algorithm and quantile normalization with the Affymetrix Power Tools, version 1.12.0, and platform-specific library files. Differential gene expression was analyzed using descriptive statistics (fold change) and Student’s T-Test method for pairwise comparisons. Genes were prioritized by statistical evidence. In order to create candidate lists for differential gene expression between conditions, we used all genes regulated at least 1.5-fold where differential expression was significant at level 0.05. Type I error inflation was ignored because the p-values were used to prioritize the list rather than being interpreted in a confirmatory sense.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfff23140dba29",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "messages =[\n",
    "    {'role':'system', 'content':data_processing_constitution},\n",
    "    {'role':'user', 'content':example_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a722c085a4ecea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "completion = openai_generate(messages, temperature=1.0)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2f48e10e7cc06",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89091c86e4257e3e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_extraction_message = 'Cardiac ventricle total RNA from 10 young (4-6 month) and 10 old (25-28 month) mice was prepared and hybridized to Affymetrix™GeneChip® MOE430 2.0 arrays. Total RNA was prepared from frozen tissues using the Qiagen RNeasy kit following homogenization in Trizol (Invitrogen). Genomic DNA was prepared using the Qiagen Dneasy kit.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7dbef5ea5572ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prompts.extraction_protocol import extraction_protocol_constitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70869a4de7032a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "messages =[\n",
    "    {'role':'system', 'content':extraction_protocol_constitution},\n",
    "    {'role':'user', 'content':example_extraction_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ea80a0d290355",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "completion = openai_generate(messages, temperature=1.0)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b98b4b49370c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_metadata(gse, gsm):\n",
    "    # GSE fields\n",
    "    gse_fields = ['summary', 'overall_design', 'type']\n",
    "    \n",
    "    # GSM fields\n",
    "    gsm_fields= [\n",
    "        'source_name_ch1', 'organism_ch1', 'characteristics_ch1',\n",
    "        'treatment_protocol_ch1', 'molecule_ch1', 'extract_protocol_ch1',\n",
    "        'label_ch1', 'label_protocol_ch1', 'hyb_protocol_ch1', \n",
    "        'scan_protocol', 'data_processing'\n",
    "    ]\n",
    "    \n",
    "    metadata_str = []\n",
    "    \n",
    "    # Fetch and print GSE metadata\n",
    "    for field in gse_fields:\n",
    "        value = gse.metadata.get(field, ['N/A'])[0]  # fetch metadata if available, else 'N/A'\n",
    "        metadata_str.append(f\"GSE {field.replace('_', ' ').title()}: {value}\")  # add formatted string\n",
    "    \n",
    "    # Fetch and print GSM metadata\n",
    "    for field in gsm_fields:\n",
    "        value = gsm.metadata.get(field, ['N/A'])[0]  # fetch metadata if available, else 'N/A'\n",
    "        metadata_str.append(f\"GSM {field.replace('_', ' ').title()}: {value}\")  # add formatted string\n",
    "\n",
    "    return \"\\n\".join(metadata_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8313aaf364fc2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field_values = set()\n",
    "for gse in gse_list:\n",
    "    try:\n",
    "        for gsm in gse.gsms:\n",
    "            gsm_sample = gse.gsms[gsm]\n",
    "            field_values.add(format_metadata(gse, gsm_sample))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c98bc0826ea7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(field_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ecbc97aececfd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb61a65f9db9b85",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicate_instruction = \"\"\"Introduction and Goal:\n",
    "\n",
    "The primary goal of this task is to systematically extract and standardize predicates from the metadata of GSE (Gene Expression Omnibus Series) and GSM (Gene Expression Omnibus Samples) descriptions. These predicates will be used to automate the metadata standardization process across various omics datasets, facilitating efficient and consistent data analysis for meta-studies. By defining clear predicates based on experimental design and sample collection, we aim to create a structured queryable framework that enhances data retrieval and analysis capabilities in biological research databases.\n",
    "\n",
    "Task Description:\n",
    "\n",
    "Generate a comprehensive list of predicates focused on {aspect} from GSE and GSM descriptions. Ensure each predicate is standardized, uses controlled vocabulary, and adheres strictly to the concepts outlined in the provided guidelines. This structured extraction will enable automated systems to better understand and categorize data entries, significantly improving the accuracy and speed of meta-analyses.\n",
    "\n",
    "Guidelines:\n",
    "Focus on Key Concepts from the following list:\n",
    "{aspect_details}\n",
    "\n",
    "Ensure that the list of predicates is comprehensive and covers all concepts from the list above. \n",
    "\n",
    "\n",
    "Define Predicates:\n",
    "\n",
    "For each identified relationship or attribute, define a predicate. Ensure the predicate name is descriptive of the relationship or attribute it represents.\n",
    "Create separate predicates for distinctive properties not entailed with each other (for example, strain and age).\n",
    "Avoid using free-text entries in the predicates.\n",
    "Exclude predicates that are not related to the specified key concepts. Avoid including predicates related to the following aspects: {irrelevant_aspects_combined}.\n",
    "Only include predicates relevant to {aspect}. \n",
    "Do not generate predicates for generic attributes such as age or sex unless explicitly related to the sample characteristics described in the guidelines.\n",
    "Do not generate predicates for quantitative measures such as temporal data, dosage, concentration, volume, mass, temperature, speed, time duration, and frequency. These formats are already standardized and provided. Focus on other attributes and relationships related to the specified key concepts.\n",
    "\n",
    "\n",
    "\n",
    "Standardize Quantitative Data:\n",
    "\n",
    "Ensure that quantitative data is standardized in a consistent format, such as TimeFrame(value, unit).\n",
    "Use the following formats for other quantitative measures:\n",
    "List of Standardized Quantitative Measures\n",
    "Temporal Data\n",
    "\n",
    "Format: TimeFrame(value, unit)\n",
    "Example: TimeFrame(32, Years)\n",
    "Range Format: TimeFrame(Range(minValue, maxValue), unit)\n",
    "Range Example: TimeFrame(Range(32, 39), Years)\n",
    "Dosage\n",
    "\n",
    "Format: Dosage(value, unit)\n",
    "Example: Dosage(1.0, gPerKg)\n",
    "Range Format: Dosage(Range(minValue, maxValue), unit)\n",
    "Range Example: Dosage(Range(0.5, 1.0), gPerKg)\n",
    "Concentration\n",
    "\n",
    "Format: Concentration(value, unit)\n",
    "Example: Concentration(0.1, Molar)\n",
    "Range Format: Concentration(Range(minValue, maxValue), unit)\n",
    "Range Example: Concentration(Range(0.05, 0.1), Molar)\n",
    "Volume\n",
    "\n",
    "Format: Volume(value, unit)\n",
    "Example: Volume(10, mL)\n",
    "Range Format: Volume(Range(minValue, maxValue), unit)\n",
    "Range Example: Volume(Range(5, 10), mL)\n",
    "Mass\n",
    "\n",
    "Format: Mass(value, unit)\n",
    "Example: Mass(2.5, mg)\n",
    "Range Format: Mass(Range(minValue, maxValue), unit)\n",
    "Range Example: Mass(Range(1.0, 2.5), mg)\n",
    "Temperature\n",
    "\n",
    "Format: Temperature(value, unit)\n",
    "Example: Temperature(37, Celsius)\n",
    "Range Format: Temperature(Range(minValue, maxValue), unit)\n",
    "Range Example: Temperature(Range(35, 37), Celsius)\n",
    "Speed\n",
    "\n",
    "Format: Speed(value, unit)\n",
    "Example: Speed(100, rpm)\n",
    "Range Format: Speed(Range(minValue, maxValue), unit)\n",
    "Range Example: Speed(Range(80, 100), rpm)\n",
    "Time Duration\n",
    "\n",
    "Format: Duration(value, unit)\n",
    "Example: Duration(30, Minutes)\n",
    "Range Format: Duration(Range(minValue, maxValue), unit)\n",
    "Range Example: Duration(Range(20, 30), Minutes)\n",
    "Frequency\n",
    "\n",
    "Format: Frequency(value, unit)\n",
    "Example: Frequency(3, perDay)\n",
    "Range Format: Frequency(Range(minValue, maxValue), unit)\n",
    "Range Example: Frequency(Range(2, 3), perDay)\n",
    "\n",
    "Standardize Software versions:\n",
    "Ensure that versions of the software related to {aspect} are standardized in a consistent format.\n",
    "Use the following predicate:\n",
    "Format: SoftwareVersion(softwareTitle, versionNumber)\n",
    "Example: SoftwareVersion(AffymetrixPowerTools, 1.12.0)\n",
    "\n",
    "Format the Output:\n",
    "\n",
    "Generate a list of predicates.\n",
    "Provide a brief description of what each predicate represents.\n",
    "Include an example for each predicate.\n",
    "Refrain from using sample as an argument in predicates.\n",
    "Output nothing but a list of predicates according to the provided format. Start right away with the definition of the first predicate.\n",
    "\n",
    "Output format example:\n",
    "\n",
    "Definition: somePredicate(argument)\n",
    "Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: somePredicate(ExampleArgument)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171eec9dbc375cc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_tokens_from_string(predicate_instruction, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37744c3747a8eda2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAMPLING_SIZE=150\n",
    "N_TRIALS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac54aa617de362",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refinement_prompt = \"\"\"You are given multiple lists of predicates extracted from various sets of GSE (Gene Expression Omnibus Series) and GSM (Gene Expression Omnibus Samples) metadata descriptions. These predicates are related to {aspect}. Your task involves several key steps to refine and consolidate these predicates into a single, standardized list:\n",
    "\n",
    "Merge and Deduplicate: Combine all the provided lists into one unified list. Identify and remove any duplicate predicates, ensuring that synonyms and nearly identical concepts are consolidated into a single entry. Aim for a clean, non-redundant list that captures the essence of each predicate without repetition.\n",
    "\n",
    "Standardize Format and Terminology: Review the merged list for consistency in naming conventions, formatting, and descriptions. Adjust the predicates to ensure they align with the standardized formats discussed in the guidelines. This includes using controlled vocabulary and adhering to a consistent structural format. Use adjustment examples below.\n",
    "\n",
    "Adjustment examples:\n",
    "Before: somePredicate(\"free text argument\")\n",
    "After: somePredicate(VariableLikeArgument)\n",
    "\n",
    "Before: somePredicate(Argument With Spaces)\n",
    "After: somePredicate(ArgumentWithoutSpaces)\n",
    "\n",
    "Before: somePredicate(argument_with_underscore)\n",
    "After: somePredicate(CamelCaseArgument)\n",
    "\n",
    "Validate and Refine: Ensure that each predicate in the list strictly pertains to the key concepts of {aspect}. Remove any predicates that do not conform to these guidelines or that address unrelated topics such as the following: {irrelevant_aspects_combined}. Focus on refining predicates to be as specific and relevant as possible.\n",
    "\n",
    "Format the Final Output: Organize the final list of predicates into a structured format, with definition of each predicate followed by its brief, clear description and an example of usage. Output nothing but a list of predicates in the format specified below. Start with definition of the first predicate right away.\n",
    "\n",
    "Output format example:\n",
    "\n",
    "Definition: somePredicate(argument)\n",
    "Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: somePredicate(ExampleArgument)\n",
    "\n",
    "Definition: anotherPredicate(argument)\n",
    "Description: another predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: anotherPredicate(AnotherArgument)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035a853aadb7bcc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_predicates(aspect, n_trials, sampling_size):\n",
    "    aspect_details = annotation_aspects_list[aspect]\n",
    "    irrelevant_aspects = [x for x in annotation_aspects_list.keys() if x != aspect] \n",
    "    predicate_list = []\n",
    "    for __ in range(n_trials):\n",
    "        input_samples_combined = \"List of examples to extract predicates from:\\n\"+\"\\n\\n\\n\".join(sample((list(field_values)), sampling_size))\n",
    "        resp = openai_generate([\n",
    "            {\"role\":'system',\n",
    "             'content':predicate_instruction.format(aspect=aspect,\n",
    "                                                    aspect_details=aspect_details,\n",
    "                                                    irrelevant_aspects_combined='\\n'.join(irrelevant_aspects)\n",
    "                                                    )},\n",
    "            {'role':'user',\n",
    "             'content':input_samples_combined}\n",
    "        ], model='gpt-4o')\n",
    "        predicate_list.append(resp.choices[0].message.content)\n",
    "    \n",
    "    combined_predicates = \"Draft predicate lists:\\n\"'\\n\\n###\\n'.join(predicate_list)\n",
    "    resp = openai_generate([\n",
    "            {\"role\":'system', 'content':refinement_prompt.format(aspect=aspect,\n",
    "                                                    aspect_details=aspect_details,\n",
    "                                                    irrelevant_aspects_combined='\\n'.join(irrelevant_aspects)\n",
    "                                                    )},\n",
    "            {'role':'user', 'content':combined_predicates}\n",
    "        ], model='gpt-4')\n",
    "    \n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c20463d5fded6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for aspect in annotation_aspects_list.keys():\n",
    "    predicates = extract_predicates(aspect, 5, 180)\n",
    "    with open(aspect+\".txt\", 'w') as f:\n",
    "        f.write(predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4914d84eb5d8136",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Predicate collection with each annotation_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc9b7a3c76af39",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsm_sample.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20eec2a094b16c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_unique_gsm_field_values(key='data_processing'):\n",
    "    field_values = set()\n",
    "    for gse in gse_list:\n",
    "        try:\n",
    "            for gsm in gse.gsms:\n",
    "                sample = gse.gsms[gsm]\n",
    "                field_values.update(set(sample.metadata[key]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return field_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5fecdef942e129",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsm_metadata_fields = ['treatment_protocol_ch1', 'extract_protocol_ch1', 'label_protocol_ch1', 'hyb_protocol', 'scan_protocol', 'data_processing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918add88c69c5463",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field = 'data_processing'\n",
    "unique_values = collect_unique_gsm_field_values(field)\n",
    "data_string = \"\\n###\\n\".join(list(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4222e6fbb880797",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48064e473961a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field_prompt=\"\"\"Below are multiple occurrences of the field {field} from metadata of various studies from GEO, separated by ###. The goal is to create a set of First-Order Logic (FOL) predicates to parse these protocols, ensuring they are standardized in a machine-readable format. List all aspects from the data needed to construct these predicates. Ensure the list is complete and non-redundant. Output only the list and start with the first element.\n",
    "{data_string}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f7a3d1a463d1a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aspect_message = openai_generate([\n",
    "            {\"role\":'user', 'content':field_prompt.format(field=field,\n",
    "                                                          data_string=data_string\n",
    "                                                    )},\n",
    "        ], model='gpt-4')\n",
    "print(aspect_message.choices[0].message.content)\n",
    "predicate_message = openai_generate([\n",
    "            {\"role\":'user', 'content':field_prompt.format(field=field,\n",
    "                                                          data_string=data_string\n",
    "                                                    )},\n",
    "    {\"role\":\"assistant\", 'content':resp.choices[0].message.content},\n",
    "    {\"role\":'user', 'content':'''Now generate a list of predicates to cover this list. Use the following format:\n",
    "Definition: somePredicate(argument)\n",
    "Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "Example: somePredicate(ExampleArgument)'''\n",
    "                              }\n",
    "        ], model='gpt-4', temperature=0.0)\n",
    "print(predicate_message.choices[0].message.content)\n",
    "parsing_message = openai_generate([\n",
    "            {\"role\":'user', 'content':field_prompt.format(field=field,\n",
    "                                                          data_string=data_string\n",
    "                                                    )},\n",
    "    {\"role\":\"assistant\", 'content':resp.choices[0].message.content},\n",
    "    {\"role\":'user', 'content':'Now generate a list of predicates to cover this list.'},\n",
    "    {\"role\":\"assistant\", 'content':resp2.choices[0].message.content},\n",
    "    {\"role\":'user', 'content':'Now parse each input metadata into FOL using constructed predicates. Include original text in your output. Make sure to eliminate freetext arguments and format arguments in camelcase and are not quoted.'},\n",
    "        ], model='gpt-4')\n",
    "print(parsing_message.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3a9c160cc5d6a382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:34:56.281157Z",
     "start_time": "2024-07-15T11:34:56.269739Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def extract_field_predicates(field: str) -> Dict[str, str]:\n",
    "    unique_values = collect_unique_gsm_field_values(field)\n",
    "    data_string = \"\\n###\\n\".join(list(unique_values))\n",
    "    message_list = []\n",
    "    field_prompt = \"\"\"Below are multiple occurrences of the field {field} from metadata of various studies from GEO, separated by ###. The goal is to create a set of First-Order Logic (FOL) predicates to parse these protocols, ensuring they are standardized in a machine-readable format. List all aspects from the data needed to construct these predicates. Ensure the list is complete and non-redundant. Output only the list and start with the first element.\n",
    "    {data_string}\n",
    "    \"\"\"\n",
    "    message_list.append({\"role\": 'user', 'content': field_prompt.format(field=field, data_string=data_string)})\n",
    "    aspect_message = openai_generate(message_list, model='gpt-4')\n",
    "\n",
    "    # Extracting the content of the aspect_message\n",
    "    aspect_content = aspect_message.choices[0].message.content\n",
    "    # appending the aspect message to the message list\n",
    "    message_list.append({\"role\": \"assistant\", 'content': aspect_content})\n",
    "\n",
    "    message_list.append({\n",
    "        \"role\": 'user',\n",
    "        'content': '''Now generate a list of predicates to cover this list. Use the following format:\n",
    "        Definition: somePredicate(argument)\n",
    "        Description: some predicate given for example. Actual predicates will have a meaningful description here.\n",
    "        Example: somePredicate(ExampleArgument)'''\n",
    "    })\n",
    "    predicate_message = openai_generate(message_list, model='gpt-4', temperature=0.0)\n",
    "\n",
    "    # Extracting the content of the predicate_message\n",
    "    predicate_content = predicate_message.choices[0].message.content\n",
    "    # appending the predicate message to the message list\n",
    "    message_list.append({\"role\": \"assistant\", 'content': predicate_content})\n",
    "\n",
    "    message_list.append({\n",
    "        \"role\": 'user',\n",
    "        'content': 'Now parse each input metadata into FOL using constructed predicates. Include original text in your output. Make sure to eliminate freetext arguments and format arguments in camelcase and are not quoted.'\n",
    "    })\n",
    "    parsing_message = openai_generate(message_list, model='gpt-4')\n",
    "\n",
    "    # Extracting the contents of the parsing_message\n",
    "    parsing_content = parsing_message.choices[0].message.content\n",
    "\n",
    "    return {\"aspects\": aspect_content, \"predicates\": predicate_content, \"parsed\": parsing_content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9dd20579d4969ff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:36:35.327265Z",
     "start_time": "2024-07-15T11:34:56.754949Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'GDS' object has no attribute 'gsms'\n",
      "'hyb_protocol'\n"
     ]
    }
   ],
   "source": [
    "content = extract_field_predicates('hyb_protocol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6cebe579e8a1c62a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:37:24.774937Z",
     "start_time": "2024-07-15T11:37:24.769137Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Protocol Name or Source\n",
      "2. Hybridization procedure\n",
      "3. Temperature for Hybridization\n",
      "4. Duration of Hybridization\n",
      "5. Type of RNA \n",
      "6. Quantity of RNA\n",
      "7. Type of Chip or Array\n",
      "8. Washing and Staining procedure\n",
      "9. Fluidic Station used\n",
      "10. Manufacturer of Materials\n",
      "11. Hybridization Kit Used\n",
      "12. Address/location of Manufacturer\n",
      "13. Type of DNA (if any)\n",
      "14. Labeling method for RNA or DNA\n",
      "15. Amplification of cRNA\n",
      "16. Biotinylation of cRNA\n",
      "17. Fragmentation of cRNA and its quantity.\n"
     ]
    }
   ],
   "source": [
    "print(content['aspects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c4d69ec8bc8055b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:22:47.240348Z",
     "start_time": "2024-07-15T12:22:47.219621Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"According to Illumina protocols\"\n",
      "protocolName(IlluminaProtocols)\n",
      "\n",
      "2. \"Following fragmentation, cRNA were hybridized onto the Affymetrix GeneChip Mouse Genome 430 2.0 arrays using the standard Affymetrix protocol. GeneChips were washed and stained in the Affymetrix Fluidics Station 450.\"\n",
      "hybridizationProcedure(HybridizedAffymetrixGeneChipMouseGenome430Arrays)\n",
      "rnaType(CRNA)\n",
      "chipType(AffymetrixGeneChipMouseGenome430)\n",
      "washingProcedure(WashedAndStainedAffymetrixFluidicsStation450)\n",
      "fluidicStation(AffymetrixFluidicsStation450)\n",
      "\n",
      "3. \"700 ng of biotinylated cRNA was hybridized to a BeadChip at 580C for 16-17 hours.\"\n",
      "rnaQuantity(700Ng)\n",
      "rnaType(BiotinylatedCRNA)\n",
      "hybridizationProcedure(HybridizedToBeadChip)\n",
      "hybridizationTemperature(580C)\n",
      "hybridizationDuration(16To17Hours)\n",
      "\n",
      "4. \"Standard Illumina protocol\"\n",
      "protocolName(StandardIllumina)\n",
      "\n",
      "5. \"Affymetrix Eukaryotic Target Hybridization protocol for 100 Format midi arrays (GeneChip® Expression Analysis Technical Manual 701021 Rev. 5)\"\n",
      "protocolName(AffymetrixEukaryoticTargetHybridization)\n",
      "chipType(FormatMidiArrays)\n",
      "\n",
      "6. \"According to the manufacturer's instructions.\"\n",
      "protocolName(ManufacturersInstructions)\n",
      "\n",
      "7. \"Following fragmentation, 10 ug of cRNA were hybridized for 16 hr at 45C on Affymetrix mouse 430 2.0 Array. GeneChips were washed and stained in the Affymetrix Fluidics Station 400.\"\n",
      "cRNAfragmentation(Fragmented10UgCRNA)\n",
      "hybridizationDuration(16Hr)\n",
      "hybridizationTemperature(45C)\n",
      "chipType(AffymetrixMouse430Array)\n",
      "washingProcedure(WashedAndStainedAffymetrixFluidicsStation400)\n",
      "fluidicStation(AffymetrixFluidicsStation400)\n",
      "\n",
      "8. \"750 ng of amplified and Cy3-labelled RNA were used directly hybridized on the Beadchips for 16 hours at 58°C following Illumina’s instructions. Beadchips were then washed following Illumina's protocol.\"\n",
      "rnaQuantity(750Ng)\n",
      "rnaType(AmplifiedAndCy3LabelledRNA)\n",
      "hybridizationProcedure(HybridizedToBeadchips)\n",
      "hybridizationDuration(16Hrs)\n",
      "hybridizationTemperature(58C)\n",
      "washingProcedure(WashedBeadchipsIlluminaProtocol) \n",
      "\n",
      "9. \"The RNA was hybridized to the Human Genome U133A 2.0 Array (Affymetrix).\"\n",
      "hybridizationProcedure(HybridizedToHumanGenomeArray)\n",
      "rnaType(RNA)\n",
      "chipType(HumanGenomeU133AArray) \n",
      "\n",
      "10. \"Standard Illumina hybridization protocol\"\n",
      "protocolName(StandardIlluminaHybridization)\n",
      "\n",
      "11. \"The standard hybridization protocol was used as recommended by Affymterix.\"\n",
      "protocolName(StandardHybridization)\n",
      "\n",
      "12. \"Purified RNA was labeled and hybridized to RAE 230 V2.0 gene chips (one chip per region per animal) by the NIH core facility.\"\n",
      "rnaType(PurifiedRNA)\n",
      "chipType(RAE230V2GeneChips)\n",
      "hybridizationProcedure(LabeledAndHybridizedToRAE230V2)\n",
      "\n",
      "13. \"Following fragmentation, 15 microg of cRNA were hybridized for 16 hr at 45C on Affymetrix HU-133 2.0 GeneChip array.\"\n",
      "cRNAfragmentation(Fragmented15MicrogCRNA)\n",
      "hybridizationDuration(16Hr)\n",
      "hybridizationTemperature(45C)\n",
      "chipType(AffymetrixHU1332GeneChipArray)\n",
      "\n",
      "14. \"Illumina Whole Genome Gene Expression\"\n",
      "protocolName(IlluminaWholeGenomeGeneExpression)\n",
      "\n",
      "15. \"Standard Affymetrix procedures\"\n",
      "protocolName(StandardAffymetrix)\n",
      "\n",
      "16. \"GeneChip Human Genome U133_Plus_2.0 (Affymetrix) were hybridized with 10 µg amplified RNA and washed with a fluidics station 450 (Affymetrix).\"\n",
      "chipType(GeneChipHumanGenomeU133Plus2)\n",
      "rnaQuantity(10Microg)\n",
      "rnaType(AmplifiedRNA)\n",
      "hybridizationProcedure(HybridizedWithAmplifiedRNA)\n",
      "fluidicStation(AffymetrixFluidicsStation450)\n",
      "\n",
      "17. \"cDNA was synthesized from 200ng total RNA using TotalPrep™ RNA Amplification Kit (Ambion) which was followed by amplification and biotinylation of cRNA and hybridization.\"\n",
      "dnaType(CDNA)\n",
      "rnaQuantity(200Ng)\n",
      "rnaType(TotalRNA)\n",
      "hybridizationProcedure(AmplificationAndBiotinylationOfCRNAAndHybridization)\n",
      "\n",
      "18. \"Following fragmentation 10ug of cRNA were hybridized on Rat Expression 230 2.0 Genechips. GeneChips were washed and stained in the Affymetrix Fluidics Station 450.\"\n",
      "cRNAfragmentation(Fragmented10UgCRNA)\n",
      "hybridizationProcedure(HybridizedOnRatExpression230Genechips)\n",
      "chipType(RatExpression230Genechips)\n",
      "washingProcedure(WashedAndStainedInAffymetrixFluidicsStation450)\n",
      "fluidicStation(AffymetrixFluidicsStation450)\n",
      "\n",
      "19. \"Samples were hybridized according to the Affymetrix protocol\"\n",
      "hybridizationProcedure(HybridizedAccordingToAffymetrixProtocol)\n",
      "\n",
      "20. \"The labeled cDNA was hybridized to the Mouse GeneChip 430 2.0 (Affymetrix, Santa Clara, CA, USA). The GeneChip Hybridization, Wash and Stain Kit (Affymetrix, CA) was used for the hybridizations according to the protocol of the manufacturer.\"\n",
      "dnaType(LabeledCDNA)\n",
      "hybridizationProcedure(HybridizedToMouseGeneChip430)\n",
      "chipType(MouseGeneChip430)\n",
      "hybridizationKit(GeneChipHybridizationWashAndStainKit)\n"
     ]
    }
   ],
   "source": [
    "print(content['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe15d8d4c5315fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
